<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <title> Project Section</title>

    <!---------Google Font Linking-------->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@400;700&display=swap" rel="stylesheet">

    <!--Google Font Linking-->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Oswald&family=Roboto:wght@400;700&display=swap"
        rel="stylesheet">

    <!--Bootstrap cdn linking -->
    <link rel='https://cdn.jsdelivr.net/npm/bootstrap@4.4.1/dist/css/bootstrap.min.css'>

    <!--style.css linking-->
    <link rel="stylesheet" href="style.css">

    <!--Lightbox.css-->
    <link rel="stylesheet" href="lightbox.min.css"/>
</head>

<body>
    <!--Project Section-->
    <section id="project">
        <!--heading-->
        <div class="project-heading">
            <a class="link-style" href="/about.html">Abhishek Pavani</a>
            <!-- <h2 align="center">My Projects</h2> -->
        </div>

        <!--filter-->
        <ul class="project-filter">
            <li class="list project-filter-active" data-filter="all">All</li>
            <li class="list" data-filter="computer-vision">Computer Vision</li>
            <li class="list" data-filter="deep-learning">Deep Learning</li>
            <li class="list" data-filter="generative">Generative Models</li>
            <li class="list" data-filter="robotics">Robotics</li>
        </ul>

        <!--container-->
        <div class="project-container">
            
            <!--box-1-->
            <a href="#sfm" class="project-box computer-vision html5lightbox" >
                <video src="images/proj1/shoe.webm" alt="" autoplay loop></video>
                <div class="text middle">Structure from Motion</div> 
            </a>

            <!--box-1a-->
            <a href="#nerf" class="project-box computer-vision deep-learning html5lightbox" >
              <img src="images/proj1A/nerf.gif" alt="">
              <div class="text middle">Neural Radiance Fields</div> 
          </a>

            <!--box-2-->
            <a href="#3d-reconstruction" class="project-box computer-vision html5lightbox ">
                <img src="images/proj2/train.jpeg" alt="">
                <div class="text middle">Epipolar Geometry</div> 
            </a>

            <!--box-3-->
            <a href="#single-view-recon" class="project-box computer-vision html5lightbox">
                <video src="images/proj3/homepod.webm" alt="" autoplay loop></video>
                <div class="text middle">Single View 3D Reconstruction</div> 

            </a>

            <!--box-4-->
            <a href="#affine" class="project-box computer-vision html5lightbox">
                <img src="images/proj4/metric1.png" alt="">
                <div class="text middle">Image Rectification</div> 

            </a>
            
            <!--box-4A-->
            <a href="#sfm-panorama" class="project-box computer-vision html5lightbox">
                <video src="images/proj4A/abhishek.webm" alt="" autoplay loop></video>
                <div class="text middle">Recover Camera Pose from Rotation Dominant Motion</div> 

            </a>

            <!--box-5-->
            <a href="#2d-homography" class="project-box computer-vision html5lightbox">
                <video src="images/proj5/kfp.webm" alt="" loop autoplay></video>
                <div class="text middle">Planar Homography</div> 

            </a>

            <!--box-6-->
            <a href="#physics-based-vision" class="project-box computer-vision html5lightbox">
                <img src="images/proj6/face2.png" alt="">
                <div class="text middle">Photometric Stereo</div> 

            </a>
            
            <!--box-7-->
            <a href="#pytorch3d" class="project-box deep-learning html5lightbox">
                <video src="images/proj7/colored_cow.webm" autoplay loop alt=""></video>
                <div class="text middle">3D Learning basics with Pytorch3d</div> 

            </a>

            <!--box-8-->
            <a href="#alignrgb" class="project-box computer-vision html5lightbox">
                <img src="images/proj8/emir.jpeg" alt="">
                <div class="text middle">Image Registration</div> 

            </a>

            <!--box-9-->
            <a href="#defectidentification" class="project-box deep-learning html5lightbox">
                <img src="images/proj9/winddefect.png" alt="">
                <div class="text middle">Defect Identification in Wind Turbines</div> 

            </a>
            
            <!--box-10-->
            <a href="#semanticsegmentation" class="project-box deep-learning html5lightbox">
              <img src="images/proj10/segment.png" alt="">
              <div class="text middle">Semantic segmentation of high resolution aerial imagery </div> 

          </a>

            <!--box-11-->
            <a href="#robotcooking" class="project-box robotics html5lightbox">
                <video src="images/proj11/robotcook.webm" alt="" autoplay loop></video>
                <div class="text middle">Understanding and dispensing ingredients for smart robotic cooking</div> 

            </a>

            <!--box-12-->
            <a href="#legokitting" class="project-box robotics html5lightbox">
              <img src="images/proj12/legokit.jpeg" alt="">
              <div class="text middle">Lego Kitting</div> 

            </a>

            <!--box-13-->
            <a href="#fixedwing" class="project-box robotics html5lightbox">
              <img src="images/proj13/fixedwing.png" alt="">
              <div class="text middle">Design of Fixed wing UAV for package delivery</div> 

            </a>

            <!--box-14-->
            <a href="#evtol" class="project-box robotics html5lightbox">
              <img src="images/proj14/evtol.jpeg" alt="">
              <div class="text middle">Design of e-VTOL UAV with enhanced flight times</div> 

            </a>

            <!--box-15-->
            <a href="#singleviewNN" class="project-box deep-learning computer-vision html5lightbox">
              <img src="images/proj15/singleviewNN.gif" alt="">
              <div class="text middle">Single View 3D reconstruction using neural networks</div> 

            </a>

            <!--box-16-->
            <a href="#hri" class="project-box robotics html5lightbox">
              <img src="images/proj16/pepper.png" alt="">
              <div class="text middle">A study on empathy towards robots and its relation to
                anthropomorphism and robot familiarity</div> 

            </a>

            <!--box-17-->
            <!-- <a href="#kitti" class="project-box robotics deep-learning computer-vision html5lightbox">
              <img src="images/proj-16.jpg" alt="">
              <div class="text middle">Visual Odometry on Kitti Dataset</div> 

            </a> -->
            
            <!--box-18-->
            <a href="#apple" class="project-box deep-learning generative html5lightbox">
              <img src="images/proj18/realtime_index.png" alt="">
              <div class="text middle">Real Time Controllable Motion Transition for Characters</div> 

            </a>

            <!--box-19-->
            <a href="#gans" class="project-box deep-learning generative html5lightbox">
              <img src="images/proj19/obama-gan.png" alt="">
              <div class="text middle">GANs and Diffusion Model</div> 

            </a>

            <!--box-20-->
            <!-- <a href="#vqa" class="project-box deep-learning html5lightbox">
              <img src="images/proj-20.jpg" alt="">
              <div class="text middle">Visual Question Answering</div> 

            </a> -->

            <!--box-21-->
            <!-- <a href="#midas" class="project-box deep-learning html5lightbox">
              <img src="images/proj-20.jpg" alt="">
              <div class="text middle">Depth Map Prediction using transformer architecture</div> 

            </a> -->

            <!--box-22-->
            <a href="#poisson" class="project-box computer-vision html5lightbox">
              <img src="images/proj22/poisson.png" alt="">
              <div class="text middle">Gradient Domain Fusion</div> 

            </a>

            <!--box-23-->
            <a href="#nst" class="project-box computer-vision deep-learning generative html5lightbox">
              <img src="images/proj23/adarsh-starrynight-2.gif" alt="">
              <div class="text middle">Neural Style Transfer</div> 

            </a>


        </div>
        <!--Project Descriptions and details-->
        <!--proj1 SFM -->>
        <div id="sfm" style="display:none;">
            <div class="lightboxcontainer">
              <div class="lightboxleft">
                <div class="divtext">
                  <p class="divtitle" style="font-size:16px;font-weight:bold;margin:12px 0px;">Structure from Motion</p>
                  <p class="divdescription" style="font-size:14px;line-height:20px;">In this project, I have implemented algorithms for doing structure from motion. The project begins with reconstruction from triangulation using 2 input images(two view reconstruction) and then goes onto explore incremental sfm(a technique used by most modern SfM pipelines) and finally I explored COLMAP (an off the shelf application to do SfM)</p>
                  
                  <p class="divdescription" style="font-size:14px;line-height:20px;">Details of the project can be found  <a class="link-style" href="https://www.andrew.cmu.edu/course/16-822/projects/apavani2/proj4/">here</a></p>
                </div>
              </div>
              <div class="lightboxright">
                <!-- <iframe width="100%" height="100%" src="https://www.youtube.com/embed/wswxQ3mhwqQ" frameborder="0" allowfullscreen></iframe> -->
                <iframe src="images/proj1/shoe.webm" width="75%" height="75%"></iframe>
              </div>
              <div style="clear:both;"></div>
          </div></div>

        <!--proj1A NeRF -->
        <div id="nerf" style="display:none;">
            <div class="lightboxcontainer">
              <div class="lightboxleft">
                <div class="divtext">
                  <p class="divtitle" style="font-size:16px;font-weight:bold;margin:12px 0px;">Neural Radiance Fields</p>
                  <p class="divdescription" style="font-size:14px;line-height:20px;">In this project, I have implemented differentiable volume rendering. I used those concepts to perform novel view synthesis using Neural Radiance Fields (NeRFs)</p>
                  
                  <p class="divdescription" style="font-size:14px;line-height:20px;">Details of the project can be found  <a class="link-style" href="https://www.andrew.cmu.edu/course/16-825/projects/apavani2/proj3/">here</a></p>
                </div>
              </div>
              <div class="lightboxright">
                <!-- <iframe width="100%" height="100%" src="https://www.youtube.com/embed/wswxQ3mhwqQ" frameborder="0" allowfullscreen></iframe> -->
                <img src="images/proj1A/nerf.gif" width="75%" height="75%">
              </div>
              <div style="clear:both;"></div>
          </div></div>

        <!--proj2 3D Reconstruction -->>
        <div id="3d-reconstruction" style="display:none;">
            <div class="lightboxcontainer">
              <div class="lightboxleft">
                <div class="divtext">
                  <p class="divtitle" style="font-size:16px;font-weight:bold;margin:12px 0px;">Epipolar Geometry and 3D reconstruction</p>
                  <p class="divdescription" style="font-size:14px;line-height:20px;">In this project, I have implemented epipolar geometry constraints and understood its importance in generating 3D structure from 2D images. I have also implemented bundle adjustment which is used in SfM pipelines to obtain accurate camera poses</p>
                  
                  <p class="divdescription" style="font-size:14px;line-height:20px;">Details of the project can be found <a href="https://www.andrew.cmu.edu/course/16-822/projects/apavani2/proj3/">here</a></p>
                </div>
              </div>
              <div class="lightboxright">
                <!-- <iframe width="100%" height="100%" src="https://www.youtube.com/embed/wswxQ3mhwqQ" frameborder="0" allowfullscreen></iframe> -->
                <img src="images/proj2/train.jpeg" width="75%" height="75%">
              </div>
              <div style="clear:both;"></div>
          </div></div>

        <!--proj3 single view Reconstruction -->>
        <div id="single-view-recon" style="display:none;">
            <div class="lightboxcontainer">
              <div class="lightboxleft">
                <div class="divtext">
                  <p class="divtitle" style="font-size:16px;font-weight:bold;margin:12px 0px;">Single View Reconstruction</p>
                  <p class="divdescription" style="font-size:14px;line-height:20px;">In this project, I used concepts like vanishing points and perspective n-point to reconstruct 3D of a scene given a single view. Unlike SfM from triangulation which requires multiple views, this project aims to use the geometry behind planes and reconstruct 3D.</p>
                  
                  <p class="divdescription" style="font-size:14px;line-height:20px;">Details of the project can be found <a href="https://www.andrew.cmu.edu/course/16-822/projects/apavani2/proj2/">here</a></p>
                </div>
              </div>
              <div class="lightboxright">
                <!-- <iframe width="100%" height="100%" src="https://www.youtube.com/embed/wswxQ3mhwqQ" frameborder="0" allowfullscreen></iframe> -->
                <video src="images/proj3/homepod.webm" width="75%" height="75%" autoplay loop></video>
              </div>
              <div style="clear:both;"></div>
          </div></div>

        <!--proj4 Affine rectification -->>
        <div id="affine" style="display:none;">
            <div class="lightboxcontainer">
              <div class="lightboxleft">
                <div class="divtext">
                  <p class="divtitle" style="font-size:16px;font-weight:bold;margin:12px 0px;">Image Rectification</p>
                  <p class="divdescription" style="font-size:14px;line-height:20px;">In this project, I used the geometric principles from perspective projection and implemented different types of image rectification(affine and metric). Implementation of image rectification improved my understanding of lines and points at infinity, vanishing points. </p>
                  
                  <p class="divdescription" style="font-size:14px;line-height:20px;">Details of the project can be found <a href="https://www.andrew.cmu.edu/course/16-822/projects/apavani2/proj1/">here</a></p>
                </div>
              </div>
              <div class="lightboxright">
                <!-- <iframe width="100%" height="100%" src="https://www.youtube.com/embed/wswxQ3mhwqQ" frameborder="0" allowfullscreen></iframe> -->
                <img src="images/proj4/metric1.png" width="75%" height="75%">
              </div>
              <div style="clear:both;"></div>
          </div></div>

        <!--proj4A SfM from panorama style videos-->>
        <div id="sfm-panorama" style="display:none;">
            <div class="lightboxcontainer">
              <div class="lightboxleft">
                <div class="divtext">
                  <p class="divtitle" style="font-size:16px;font-weight:bold;margin:12px 0px;">Recovering Pose from Panorama style videos</p>
                  <p class="divdescription" style="font-size:14px;line-height:20px;">This is a course project done in the course 16-822: Geometry Based Methods in Vision. It is difficult to recover camera pose and structure of a scene from a video that has rotation dominant motion. In this project I have explored concepts like spherical epipolar geometry, feature tracking using Lucas Kanade Optical flow pyramids, GRIC score computation(geometric robust information criterion) and rotation averaging. We wrote a detailed paper which outlines our approach and hyperparameters we used. We empirically validate our approach using real world data and have made our repository public  </p>
                  
                  <p class="divdescription" style="font-size:14px;line-height:20px;">Details of the project can be found <a href="https://drive.google.com/file/d/13yFVjomOHOE6Vrsm38jKHJsb9VZPIhiF/view?usp=share_link">here</a></p>
                </div>
              </div>
              <div class="lightboxright">
                <img src="images/proj4A/camera.png" width="75%" height="75%">
              </div>
              <div style="clear:both;"></div>
          </div></div>

        <!--proj5 2D homography-->>
        <div id="2d-homography" style="display:none;">
            <div class="lightboxcontainer">
              <div class="lightboxleft">
                <div class="divtext">
                  <p class="divtitle" style="font-size:16px;font-weight:bold;margin:12px 0px;">Planar Homography</p>
                  <p class="divdescription" style="font-size:14px;line-height:20px;">In this project, I implemented 2D planar homography. Given enough annotations, we can transform any source plane to fit the target(destination) plane. I generated a simple augmented reality output by overlaying a movie on top of a book.  </p>
                  
                  <p class="divdescription" style="font-size:14px;line-height:20px;">Details of the project can be found in the homography section of <a href="https://www.andrew.cmu.edu/course/16-822/projects/apavani2/proj1/">this</a> page</p>
                </div>
              </div>
              <div class="lightboxright">
                <video src="images/proj5/kfp.webm " width="75%" height="75%" autoplay loop></video>
              </div>
              <div style="clear:both;"></div>
          </div></div>

        <!--proj6 Physics Based Vision-->>
        <div id="physics-based-vision" style="display:none;">
            <div class="lightboxcontainer">
              <div class="lightboxleft">
                <div class="divtext">
                  <p class="divtitle" style="font-size:16px;font-weight:bold;margin:12px 0px;">Photometric Stereo</p>
                  <p class="divdescription" style="font-size:14px;line-height:20px;">In this project, I reconstructed 3D surface, given a source image and multiple lighting conditions using physics based methods. I implemented the n dot l lighting model and understood concepts like albedo and surface normals </p>
                </div>
              </div>
              <div class="lightboxright">
                <img src="images/proj6/face2.png" width="75%" height="75%">
              </div>
              <div style="clear:both;"></div>
          </div></div>

          <!--proj7 Pytorch3d-->>
        <div id="pytorch3d" style="display:none;">
            <div class="lightboxcontainer">
              <div class="lightboxleft">
                <div class="divtext">
                  <p class="divtitle" style="font-size:16px;font-weight:bold;margin:12px 0px;">Pytorch 3D</p>
                  <p class="divdescription" style="font-size:14px;line-height:20px;">In this project, I worked on the basics of using the pytorch3D API. I worked on rendering point clouds, implicit, parametric surfaces. I also implement sampling point clouds from meshes. More details on the project can be found <a href="https://www.andrew.cmu.edu/course/16-825/projects/apavani2/proj1/">here</a></p>
                </div>
              </div>
              <div class="lightboxright">
                <video src="images/proj7/colored_cow.webm" width="75%" height="75%" autoplay loop>
              </div>
              <div style="clear:both;"></div>
          </div></div>

          <!--proj8 Image Registration-->>
        <div id="alignrgb" style="display:none;">
            <div class="lightboxcontainer">
              <div class="lightboxleft">
                <div class="divtext">
                  <p class="divtitle" style="font-size:16px;font-weight:bold;margin:12px 0px;">Image Registration</p>
                  <p class="divdescription" style="font-size:14px;line-height:20px;">In this project, I have written algorithms to align the channels of a RGB image. I used similarity metrics like SSD(sum of squared differences), NCC(Normalized Cross Correlation, ZNCC(Zero Normalized Cross Correlation). I tested my algorithms on the Prokudin-Gorskii photo collection. I also tested the algorithm on imagery taken from a hubble telescope. More details about the project can be found <a href="https://www.andrew.cmu.edu/course/16-726-sp23/projects/apavani2/proj1/">here</a></p>
                </div>
              </div>
              <div class="lightboxright">
                <img src="images/proj8/emir.jpeg" width="75%" height="75%">
              </div>
              <div style="clear:both;"></div>
          </div></div>

          <!--proj9 Defect Identification-->
        <div id="defectidentification" style="display:none;">
          <div class="lightboxcontainer">
            <div class="lightboxleft">
              <div class="divtext">
                <p class="divtitle" style="font-size:16px;font-weight:bold;margin:12px 0px;">Defect Identification using Deep Networks</p>
                <p class="divdescription" style="font-size:14px;line-height:20px;">The goal of this project was to identify defects in a wind turbine blade using object detection methods. For this project, I used Faster R-CNN network with a ResNet architecture to detect 9 different types of defects in images. The images of these wind turbine blades were captured from a drone. To make the processing of these images faster, I used a multi-scale pyramid network, to cater for the varying size of defects since the distance of the captured images may vary.</p>
                <p class="divdescription" style="font-size:14px;line-height:20px;">As a result of this implementation we got the defect identification time from 1 day to 15 mins. This helped us deliver results faster to our clients.</p>
              </div>
            </div>
            <div class="lightboxright">
              <figure>
              <img src="images/proj9/winddefect.png" width="75%" height="75%">
              <figcaption>Source: Pigeon Innovative Solutions LLP</figcaption>
              </figure>
            </div>
            <div style="clear:both;"></div>
        </div></div>

        <!--proj10 Semantic Segmentation-->
        <div id="semanticsegmentation" style="display:none;">
          <div class="lightboxcontainer">
            <div class="lightboxleft">
              <div class="divtext">
                <p class="divtitle" style="font-size:16px;font-weight:bold;margin:12px 0px;">Semantic Segmentation in high resolution aerial imagery</p>
                <p class="divdescription" style="font-size:14px;line-height:20px;">In this project, I worked on generating semantic segmentation masks for buildings in high resolution aerial imagery. This is useful for creating maps from captured drone imagery.</p>
                <p class="divdescription" style="font-size:14px;line-height:20px;">To create a dataset, I used high resolution 4K aerial imagery with 4cm GSD and created ground truth segmentation masks using a GIS software like QGIS. I then preprocessed these images and fed this into a UNet architecture and treated it as a supervised learning problem.</p>
                <!-- <p class="divdescription" style="font-size:14px;line-height:20px;"></p> -->
              </div>
            </div>
            <div class="lightboxright">
              <img src="images/proj10/segment.png" width="75%" height="75%">
            </div>
            <div style="clear:both;"></div>
        </div></div>

        <!--proj11 Robot cooking-->
        <div id="robotcooking" style="display:none;">
          <div class="lightboxcontainer">
            <div class="lightboxleft">
              <div class="divtext">
                <p class="divtitle" style="font-size:16px;font-weight:bold;margin:12px 0px;">Understanding and dispensing ingredients for smart robotic cooking</p>
                <p class="divdescription" style="font-size:14px;line-height:20px;">In this project, we have developed an end-end robotic system capable of making food recipes from scratch from a single click. The system is capable of identifying and validating ingredients kept in container, dispense a wide variety of ingredients including solids, liquids and powders.</p>
                <p class="divdescription" style="font-size:14px;line-height:20px;">More details about the project can be found <a href="https://mrsdprojects.ri.cmu.edu/2022teamb/">here</a></p>
              </div>
            </div>
            <div class="lightboxright">
              <video src="images/proj11/robotcook.webm" width="75%" height="75%" autoplay loop></video>
            </div>
            <div style="clear:both;"></div>
        </div></div>

        <!--proj12 Lego Kitting-->
        <div id="legokitting" style="display:none;">
          <div class="lightboxcontainer">
            <div class="lightboxleft">
              <div class="divtext">
                <p class="divtitle" style="font-size:16px;font-weight:bold;margin:12px 0px;">Lego Kitting</p>
                <p class="divdescription" style="font-size:14px;line-height:20px;">In this project, we worked on developing a robot that could sort different types of lego blocks based on color. We used image centroid and image moments to identify the camera blocks and then generated transforms from the camera frame to the robot end-effector frame to control the robot inorder to pick up the block of choice. The robot stops once it has sorted out all the blocks based on color.</p>
                <p class="divdescription" style="font-size:14px;line-height:20px;">More details about the project can be found in <a href="https://drive.google.com/file/d/1w5zNU4thTL4BeupuzLITmck0K93oKr9X/view">this</a> report.</p> 
                <p class="divdescription" style="font-size:14px;line-height:20px;"> A video link to our system in action can be found <a href="https://drive.google.com/file/d/1yqwXNROLpTAur50008b9DTNPVBMDlK0u/view">here</a></p>
                
              </div>
            </div>
            <div class="lightboxright">
              <img src="images/proj12/legokit.jpeg" width="75%" height="75%">
            </div>
            <div style="clear:both;"></div>
        </div></div>

        <!--proj13 Fixed Wing-->
        <div id="fixedwing" style="display:none;">
          <div class="lightboxcontainer">
            <div class="lightboxleft">
              <div class="divtext">
                <!-- <p class="divtitle" style="font-size:16px;font-weight:bold;margin:12px 0px;">Image Registration</p>
                <p class="divdescription" style="font-size:14px;line-height:20px;">In this project, I have written algorithms to align the channels of a RGB image. I used similarity metrics like SSD(sum of squared differences), NCC(Normalized Cross Correlation, ZNCC(Zero Normalized Cross Correlation). I tested my algorithms on the Prokudin-Gorskii photo collection. I also tested the algorithm on imagery taken from a hubble telescope. More details about the project can be found <a href="https://www.andrew.cmu.edu/course/16-726-sp23/projects/apavani2/proj1/">here</a></p> -->
                <iframe src="fixedwing.pdf" width=900px height=1000px></iframe>
              </div>
            </div>
            <div class="lightboxright">
              <!-- <img src="images/proj13/fixedwing.png" width="75%" height="75%"> -->
            </div>
            <div style="clear:both;"></div>
        </div></div>

        <!--proj14 E-VTOL UAV-->
        <div id="evtol" style="display:none;">
          <div class="lightboxcontainer">
            <div class="lightboxleft">
              <div class="divtext">
                <p class="divtitle" style="font-size:16px;font-weight:bold;margin:12px 0px;">E-VTOL UAV with swappable payloads</p>
                <p class="divdescription" style="font-size:14px;line-height:20px;">The goal of this project was to create an e-VTOL UAV with swappable payloads. I designed and fabricated this VTOL from scratch. The aircraft can stay afloat for 1.5 hrs while carrying 1kg payload onboard. It is controlled by ardupilot firmware and uses li-ion batteries to power the aircraft. The aircraft was made to survey/map large areas without landing.</p>
                <!-- <p class="divdescription" style="font-size:14px;line-height:20px;">More details about the project can be found <a href="https://www.andrew.cmu.edu/course/16-726-sp23/projects/apavani2/proj1/">here</a></p> -->
              </div>
            </div>
            <div class="lightboxright">
              <img src="images/proj14/evtol.jpeg" width="75%" height="75%">
            </div>
            <div style="clear:both;"></div>
        </div></div>

        <!--proj15 single view NN-->
        <div id="singleviewNN" style="display:none;">
          <div class="lightboxcontainer">
            <div class="lightboxleft">
              <div class="divtext">
                <p class="divtitle" style="font-size:16px;font-weight:bold;margin:12px 0px;">Image Registration</p>
                <p class="divdescription" style="font-size:14px;line-height:20px;">In this project, I have used supervised learning approaches to reconstruct 3D of an object using a single image. I explored different network architectures to output different 3D representation. I have done an empirical study to see which 3D representation is kind of useful when inferring 3D objects from single images.
                <p class="divdescription" style="font-size:14px;line-height:20px;">More details about the project can be found <a href="https://www.andrew.cmu.edu/course/16-825/projects/apavani2/proj2/">here</a></p>
              </div>
            </div>
            <div class="lightboxright">
              <img src="images/proj15/singleviewNN.gif" width="75%" height="75%">
            </div>
            <div style="clear:both;"></div>
        </div></div>

        <!--proj16 HRI-->
        <div id="hri" style="display:none;">
          <div class="lightboxcontainer">
            <div class="lightboxleft">
              <div class="divtext">
                <!-- <p class="divtitle" style="font-size:16px;font-weight:bold;margin:12px 0px;">Image Registration</p> -->
                <!-- <p class="divdescription" style="font-size:14px;line-height:20px;">In this project, I have written algorithms to align the channels of a RGB image. I used similarity metrics like SSD(sum of squared differences), NCC(Normalized Cross Correlation, ZNCC(Zero Normalized Cross Correlation). I tested my algorithms on the Prokudin-Gorskii photo collection. I also tested the algorithm on imagery taken from a hubble telescope. More details about the project can be found <a href="https://www.andrew.cmu.edu/course/16-726-sp23/projects/apavani2/proj1/">here</a></p> -->
                <iframe src="hri.pdf" width=900px height=1000px></iframe>
              </div>
            </div>
            <div class="lightboxright">
              <!-- <img src="images/proj16/pepper.png" width="75%" height="75%"> -->
            </div>
            <div style="clear:both;"></div>
        </div></div>

        <!-- proj17 VO Kitti
        <div id="kitti" style="display:none;">
          <div class="lightboxcontainer">
            <div class="lightboxleft">
              <div class="divtext">
                <p class="divtitle" style="font-size:16px;font-weight:bold;margin:12px 0px;">Image Registration</p>
                <p class="divdescription" style="font-size:14px;line-height:20px;">In this project, I have written algorithms to align the channels of a RGB image. I used similarity metrics like SSD(sum of squared differences), NCC(Normalized Cross Correlation, ZNCC(Zero Normalized Cross Correlation). I tested my algorithms on the Prokudin-Gorskii photo collection. I also tested the algorithm on imagery taken from a hubble telescope. More details about the project can be found <a href="https://www.andrew.cmu.edu/course/16-726-sp23/projects/apavani2/proj1/">here</a></p>
              </div>
            </div>
            <div class="lightboxright">
              <img src="images/proj8/emir.png" width="75%" height="75%">
            </div>
            <div style="clear:both;"></div>
        </div></div> -->

        <!--proj18 Apple Internship-->
        <div id="apple" style="display:none;">
          <div class="lightboxcontainer">
            <div class="lightboxleft">
              <div class="divtext">
                <p class="divtitle" style="font-size:16px;font-weight:bold;margin:12px 0px;">Real Time Controllable Motion Transition for Characters</p>
                <p class="divdescription" style="font-size:14px;line-height:20px;">I implemented this paper from scratch during my internship at Apple. The idea is to use a neural network to interpolate between 2 animation keyframes using a generative model. </p>
                
                <p class="divdescription" style="font-size:14px;line-height:20px;">The input data here are .bvh files, from which we extract the joint position and rotations for each frame. We feed the pose information to the encoder of the conditional-VAE to generate a latent space. We then sample from this latent space and pass it through a decoder which has multiple expert networks. The gating scheme allows for the network to choose the right expert from the decoder.</p>
                
                <p class="divdescription" style="font-size:14px;line-height:20px;">The VAE network is trained using multiple loss terms like reconstruction loss, KL Divergence, Bone Length Loss, Footskating Loss, L1 Rotation loss. These loss functions constrain the generated pose to some acceptable human pose.</p>
                
                <p class="divdescription" style="font-size:14px;line-height:20px;">Next we train a transition sampler, which takes in the current frame and the target frame and outputs the next frame in the sequence. The network architecture used for this has been mentioned in the paper. </p>
              </div>
            </div>
            <div class="lightboxright">
              <figure> 
                <img src="images/proj18/realtime.png" width="600px" height="250px">
                <figcaption>Source: <a href="https://arxiv.org/pdf/2205.02540.pdf">Paper from which the image was borrowed</a></figcaption> 
                <figcaption>Source: <a href=" https://www.youtube.com/watch?v=xgpw6WXs3Ig">Video from original authors</a></figcaption>
              </figure>
            </div>
            <div style="clear:both;"></div>
        </div></div>

        <!-- proj19 gans -->
        <div id="gans" style="display:none;">
          <div class="lightboxcontainer">
            <div class="lightboxleft">
              <div class="divtext">
                <p class="divtitle" style="font-size:16px;font-weight:bold;margin:12px 0px;">GANs and Diffusion Model</p>
                <p class="divdescription" style="font-size:14px;line-height:20px;">In this project, I implemented 2 different GAN network architectures, DCGAN and CycleGAN. I tested my implementation over 2 different datasets and have reported my findings. I also implemented the DDPM model from scratch to recover images from noise. More details about the project can be found <a href="https://www.andrew.cmu.edu/course/16-726-sp23/projects/apavani2/proj3/">here</a></p>
              </div>
            </div>
            <div class="lightboxright">
              <img src="images/proj19/obama-gan.png" width="75%" height="75%">
            </div>
            <div style="clear:both;"></div>
        </div></div>

        <!--proj20 VQA-->
        <!-- <div id="vqa" style="display:none;">
          <div class="lightboxcontainer">
            <div class="lightboxleft">
              <div class="divtext">
                <p class="divtitle" style="font-size:16px;font-weight:bold;margin:12px 0px;">Image Registration</p>
                <p class="divdescription" style="font-size:14px;line-height:20px;">In this project, I have written algorithms to align the channels of a RGB image. I used similarity metrics like SSD(sum of squared differences), NCC(Normalized Cross Correlation, ZNCC(Zero Normalized Cross Correlation). I tested my algorithms on the Prokudin-Gorskii photo collection. I also tested the algorithm on imagery taken from a hubble telescope. More details about the project can be found <a href="https://www.andrew.cmu.edu/course/16-726-sp23/projects/apavani2/proj1/">here</a></p>
              </div>
            </div>
            <div class="lightboxright">
              <img src="images/proj8/emir.png" width="75%" height="75%">
            </div>
            <div style="clear:both;"></div>
        </div></div> -->

        <!--proj21 Depth prediction using transformer architecture -->
        <!-- <div id="midas" style="display:none;">
          <div class="lightboxcontainer">
            <div class="lightboxleft">
              <div class="divtext">
                <p class="divtitle" style="font-size:16px;font-weight:bold;margin:12px 0px;">Image Registration</p>
                <p class="divdescription" style="font-size:14px;line-height:20px;">In this project, I have written algorithms to align the channels of a RGB image. I used similarity metrics like SSD(sum of squared differences), NCC(Normalized Cross Correlation, ZNCC(Zero Normalized Cross Correlation). I tested my algorithms on the Prokudin-Gorskii photo collection. I also tested the algorithm on imagery taken from a hubble telescope. More details about the project can be found <a href="https://www.andrew.cmu.edu/course/16-726-sp23/projects/apavani2/proj1/">here</a></p>
              </div>
            </div>
            <div class="lightboxright">
              <img src="images/proj8/emir.png" width="75%" height="75%">
            </div>
            <div style="clear:both;"></div>
        </div></div> -->

        <!--proj21a Weakly supervised deep detection networks -->
        <!-- <div id="weaksuper" style="display:none;">
          <div class="lightboxcontainer">
            <div class="lightboxleft">
              <div class="divtext">
                <p class="divtitle" style="font-size:16px;font-weight:bold;margin:12px 0px;">Weakly Supervised Deep detection networks</p>
                <p class="divdescription" style="font-size:14px;line-height:20px;">In this project, I have written algorithms to align the channels of a RGB image. I used similarity metrics like SSD(sum of squared differences), NCC(Normalized Cross Correlation, ZNCC(Zero Normalized Cross Correlation). I tested my algorithms on the Prokudin-Gorskii photo collection. I also tested the algorithm on imagery taken from a hubble telescope. More details about the project can be found <a href="https://www.andrew.cmu.edu/course/16-726-sp23/projects/apavani2/proj1/">here</a></p>
              </div>
            </div>
            <div class="lightboxright">
              <img src="images/proj8/emir.png" width="75%" height="75%">
            </div>
            <div style="clear:both;"></div>
        </div></div> -->

        <!--proj22 Gradient Domain Fusion -->
        <div id="poisson" style="display:none;">
          <div class="lightboxcontainer">
            <div class="lightboxleft">
              <div class="divtext">
                <p class="divtitle" style="font-size:16px;font-weight:bold;margin:12px 0px;">Gradient Domain Fusion</p>
                <p class="divdescription" style="font-size:14px;line-height:20px;">In this project, I explored gradient domain fusion techniques. In particular, I implemented poisson blending, to blend 2 images.

                The goal is to seamlessly blend an object or texture from a source image into a target image, without creating noticeable seams. The approach is to preserve the gradient of the source region while ignoring the overall intensity, using a least squares problem to solve for new intensity values within the source region. The method presented is one example of a more general set of gradient-domain processing techniques, with applications including blending, tone-mapping, and non-photorealistic rendering. The project involves implementing the Poisson blending technique and potentially exploring additional techniques as well.

                The reason why “Poisson Blending” produces a more realistic composition than simply pasting two similarly colored images together is that our visual system is more responsive to changes in contrast rather than variations in intensity.
                More details about the project can be found <a href="https://www.andrew.cmu.edu/course/16-726-sp23/projects/apavani2/proj2/">here</a></p>
              </div>
            </div>
            <div class="lightboxright">
              <img src="images/proj22/poisson.png" width="75%" height="75%">
            </div>
            <div style="clear:both;"></div>
        </div></div>

        <!--proj23 Neural Style Transfer -->
        <div id="nst" style="display:none;">
          <div class="lightboxcontainer">
            <div class="lightboxleft">
              <div class="divtext">
                <p class="divtitle" style="font-size:16px;font-weight:bold;margin:12px 0px;">Neural Style Transfer</p>
                <p class="divdescription" style="font-size:14px;line-height:20px;">In this project, I explored neural style transfer. The idea is to have a style image and a content image and then we try to copy the style from the style image while keeping the content in the content image the same. 

                
                More details about the project can be found <a href="https://www.andrew.cmu.edu/course/16-726-sp23/projects/apavani2/proj4/">here</a></p>
              </div>
            </div>
            <div class="lightboxright">
              <img src="images/proj23/adarsh-starrynight-2.gif" width="75%" height="75%">
            </div>
            <div style="clear:both;"></div>
        </div></div>

    </section>

    <!-- <header class="header">
        <div class="wrap d-flex">
            <h1 class="logo">
                <a href=""><img src="images/logo.png" alt=""></a>
            </h1>
            <nav class="menu">
                <ul>
                    <li><a href="">About Me</a></li>
                    <li><a href="">Projects</a></li>
                    <li><a href="">Contact</a></li>
                </ul>
            </nav>
        </div>

        <a href="javascript:void(0);" class="sidemenu-toggler">
            <span></span>
            <span></span>
            <span></span>
        </a>

        <div class="sidemenu">
            <a href="javascript:void(0);" class="close"></a>
            <nav>
                <ul>
                    <li><a href="">About Me</a></li>
                    <li><a href="">Projects</a></li>
                    <li><a href="">Contact</a></li>
                </ul>
            </nav>
            <footer>
                <p> © Made by Abhishek Pavani </p>
            </footer>
        </div>   
    </header>
         -->





    <script src="https://code.jquery.com/jquery-3.6.3.js"></script>
    <script type="text/javascript">
        /*--for-filter-menu--*/
        $(document).on('click', '.project-filter li', function () {
            $(this).addClass('project-filter-active').siblings().removeClass('project-filter-active')
        });

        /*--for-project/work-filter--*/
        $(document).ready(function () {
            $('.list').click(function () {
                const value = $(this).attr('data-filter');
                if (value == 'all') {
                    $('.project-box').show('1000');
                }
                else {
                    $('.project-box').not('.' + value).hide('1000');
                    $('.project-box').filter('.' + value).show('1000');
                }
            });
        });
    </script>
    <script type="text/javascript" src="html5lightbox/html5lightbox.js"></script>
</body>

</html>